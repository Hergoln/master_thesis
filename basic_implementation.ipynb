{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic implementation\n",
    "\n",
    "- load file\n",
    "  - ~~load file with encoded function~~\n",
    "  - ~~turn it into a numpy array~~\n",
    "- noise (preprocessing)\n",
    "  - ~~scale vector into -1 - 1 range~~\n",
    "  - add noise into vectors values\n",
    "  - rescale vector into values range 0-246\n",
    "- pass it through a model\n",
    "  - create a simple model (does not have to be diffusion)\n",
    "  - develop loss function\n",
    "  - implement diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# IMPORTANTE\n",
    "DICTIONARY_SIZE = 246\n",
    "TOKENS_CAPACITY = 2048\n",
    "\n",
    "def prepare_record(parsed_file):\n",
    "  parsed = np.loadtxt(parsed_file, dtype=float)\n",
    "  return parsed\n",
    "\n",
    "'''\n",
    "  Because code files weight very little they can all be loaded at once\n",
    "'''\n",
    "c_dir = \"./data/JL/\"\n",
    "parsed_dir = \"./data/parsed/\" # might change ofc\n",
    "\n",
    "'''\n",
    "  returns: tuple (np.array of encoded vectors, file names)\n",
    "'''\n",
    "def load_dataset(parsed_dir) -> list:\n",
    "  parsed_files = sorted(os.listdir(parsed_dir))\n",
    "\n",
    "  # TODO: when script is ready, remove this line\n",
    "  parsed_files = parsed_files[:256]\n",
    "\n",
    "  \n",
    "  with ThreadPool() as pool:\n",
    "    parsed_files = pool.map(lambda f: f\"{parsed_dir}{f}\", parsed_files)\n",
    "    files = list(parsed_files)\n",
    "\n",
    "  with ThreadPool() as pool:\n",
    "    # pool.map guaranteese to preserve order\n",
    "    # pool.map 'consumes' mapping created in previous with block\n",
    "    # map() function returns a generator that is exhausted after is it used\n",
    "    return [np.array(pool.map(lambda file: prepare_record(file), files)), files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(parsed_dir)\n",
    "print(dataset[0].shape)\n",
    "print(len(dataset[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(dataframe):\n",
    "  return (dataframe + 1) * DICTIONARY_SIZE / 2\n",
    "\n",
    "def scale(dataframe):\n",
    "  return (dataframe * 2 / DICTIONARY_SIZE) - 1\n",
    "\n",
    "dataset[0] = scale(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on [ddim](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/ddim.ipynb#scrollTo=8s3L-z9pcdMc)\n",
    "\n",
    "Very important is to set up a learning process and architecture of my solution.\n",
    "Exact network that is going to be used does not really mattter, will be simple FC NN and will possibly change in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "num_epochs = 1  # train for at least 50 epochs for good results\n",
    "# KID = Kernel Inception Distance, see related section\n",
    "kid_diffusion_steps = 5\n",
    "plot_diffusion_steps = 20\n",
    "\n",
    "# sampling\n",
    "min_signal_rate = 0.02\n",
    "max_signal_rate = 0.95\n",
    "\n",
    "# architecture\n",
    "embedding_dims = 32\n",
    "embedding_max_frequency = 1000.0\n",
    "widths = [32, 64, 96, 128]\n",
    "block_depth = 2\n",
    "\n",
    "# optimization\n",
    "batch_size = 64\n",
    "ema = 0.999\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get network with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x):\n",
    "    embedding_min_frequency = 1.0\n",
    "    frequencies = tf.exp(\n",
    "        tf.linspace(\n",
    "            tf.math.log(embedding_min_frequency),\n",
    "            tf.math.log(embedding_max_frequency),\n",
    "            embedding_dims // 2,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    angular_speeds = 2.0 * math.pi * frequencies\n",
    "    embeddings = tf.concat(\n",
    "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=1\n",
    "    )\n",
    "    return embeddings\n",
    "  \n",
    "def get_network(tokens_capacity):\n",
    "    noisy_images = keras.Input(shape=(tokens_capacity))\n",
    "    noise_variances = keras.Input(shape=(1))\n",
    "\n",
    "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
    "\n",
    "    x = layers.Dense(32)(noisy_images)\n",
    "    x = layers.Concatenate()([x, e])\n",
    "    x = layers.Dense(1024, kernel_initializer=\"zeros\")(x)\n",
    "    x = layers.Dense(2048, kernel_initializer=\"zeros\")(x)\n",
    "\n",
    "    return keras.Model([noisy_images, noise_variances], x, name=\"simple net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I removed KID metrics part the sample is not generated inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(keras.Model):\n",
    "    def __init__(self, tokens_capacity):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tokens_capacity = tokens_capacity\n",
    "        self.network = get_network(tokens_capacity)\n",
    "        self.ema_network = keras.models.clone_model(self.network)\n",
    "\n",
    "    def compile(self, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.noise_loss_tracker = keras.metrics.Mean(name=\"n_loss\")\n",
    "        self.sample_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # return [self.noise_loss_tracker, self.sample_loss_tracker, self.kid]\n",
    "        return [self.noise_loss_tracker, self.sample_loss_tracker]\n",
    "\n",
    "    def normalize(self, samples):\n",
    "        return (samples * 2 / DICTIONARY_SIZE) - 1\n",
    "\n",
    "    def denormalize(self, samples):\n",
    "        return (samples + 1) * DICTIONARY_SIZE / 2\n",
    "\n",
    "    def diffusion_schedule(self, diffusion_times):\n",
    "        # diffusion times -> angles\n",
    "        start_angle = tf.acos(max_signal_rate)\n",
    "        end_angle = tf.acos(min_signal_rate)\n",
    "\n",
    "        diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
    "\n",
    "        # angles -> signal and noise rates\n",
    "        signal_rates = tf.cos(diffusion_angles)\n",
    "        noise_rates = tf.sin(diffusion_angles)\n",
    "        # note that their squared sum is always: sin^2(x) + cos^2(x) = 1\n",
    "\n",
    "        return noise_rates, signal_rates\n",
    "\n",
    "    def denoise(self, noisy_samples, noise_rates, signal_rates, training):\n",
    "        # the exponential moving average weights are used at evaluation\n",
    "        if training:\n",
    "            network = self.network\n",
    "        else:\n",
    "            network = self.ema_network\n",
    "\n",
    "        # predict noise component and calculate the sample component using it\n",
    "        pred_noises = network([noisy_samples, noise_rates**2], training=training)\n",
    "        pred_samples = (noisy_samples - noise_rates * pred_noises) / signal_rates\n",
    "\n",
    "        return pred_noises, pred_samples\n",
    "\n",
    "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
    "        # reverse diffusion = sampling\n",
    "        num_samples = initial_noise.shape[0]\n",
    "        step_size = 1.0 / diffusion_steps\n",
    "\n",
    "        # important line:\n",
    "        # at the first sampling step, the \"noisy sample\" is pure noise\n",
    "        # but its signal rate is assumed to be nonzero (min_signal_rate)\n",
    "        next_noisy_samples = initial_noise\n",
    "        for step in range(diffusion_steps):\n",
    "            noisy_samples = next_noisy_samples\n",
    "\n",
    "            # separate the current noisy sample to its components\n",
    "            diffusion_times = tf.ones((num_samples)) - step * step_size\n",
    "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "            pred_noises, pred_samples = self.denoise(\n",
    "                noisy_samples, noise_rates, signal_rates, training=False\n",
    "            )\n",
    "            # network used in eval mode\n",
    "\n",
    "            # remix the predicted components using the next signal and noise rates\n",
    "            next_diffusion_times = diffusion_times - step_size\n",
    "            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n",
    "                next_diffusion_times\n",
    "            )\n",
    "            next_noisy_samples = (\n",
    "                next_signal_rates * pred_samples + next_noise_rates * pred_noises\n",
    "            )\n",
    "            # this new noisy sample will be used in the next step\n",
    "\n",
    "        return pred_samples\n",
    "\n",
    "    def generate(self, num_samples, diffusion_steps):\n",
    "        # noise -> samples -> denormalized samples\n",
    "        initial_noise = tf.random.normal(shape=(num_samples, self.tokens_capacity))\n",
    "        generated_sample = self.reverse_diffusion(initial_noise, diffusion_steps)\n",
    "        generated_sample = self.denormalize(generated_sample)\n",
    "        return generated_sample\n",
    "\n",
    "    def train_step(self, samples):\n",
    "        # normalize samples to have standard deviation of 1, like the noises\n",
    "        samples = self.normalize(samples)\n",
    "        noises = tf.random.normal(shape=(batch_size, ))\n",
    "\n",
    "        # sample uniform random diffusion times\n",
    "        diffusion_times = tf.random.uniform(\n",
    "            shape=(batch_size, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "        # mix the samples with noises accordingly\n",
    "        noisy_samples = signal_rates * samples + noise_rates * noises\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # train the network to separate noisy samples to their components\n",
    "            pred_noises, pred_samples = self.denoise(\n",
    "                noisy_samples, noise_rates, signal_rates, training=True\n",
    "            )\n",
    "\n",
    "            noise_loss = self.loss(noises, pred_noises)  # used for training\n",
    "            sample_loss = self.loss(samples, pred_samples)  # only used as metric\n",
    "\n",
    "        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
    "\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "        self.sample_loss_tracker.update_state(sample_loss)\n",
    "\n",
    "        # track the exponential moving averages of weights\n",
    "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
    "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
    "\n",
    "        # KID is not measured during the training phase for computational efficiency\n",
    "        return {m.name: m.result() for m in self.metrics[:-1]}\n",
    "\n",
    "    def test_step(self, samples):\n",
    "        # normalize samples to have standard deviation of 1, like the noises\n",
    "        samples = self.normalize(samples)\n",
    "        noises = tf.random.normal(shape=(batch_size, self.tokens_capacity))\n",
    "\n",
    "        # sample uniform random diffusion times\n",
    "        diffusion_times = tf.random.uniform(\n",
    "            shape=(batch_size, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "        # mix the samples with noises accordingly\n",
    "        noisy_samples = signal_rates * samples + noise_rates * noises\n",
    "\n",
    "        # use the network to separate noisy samples to their components\n",
    "        pred_noises, pred_samples = self.denoise(\n",
    "            noisy_samples, noise_rates, signal_rates, training=False\n",
    "        )\n",
    "\n",
    "        noise_loss = self.loss(noises, pred_noises)\n",
    "        sample_loss = self.loss(samples, pred_samples)\n",
    "\n",
    "        self.sample_loss_tracker.update_state(sample_loss)\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionModel(TOKENS_CAPACITY)\n",
    "# below tensorflow 2.9:\n",
    "# pip install tensorflow_addons\n",
    "# import tensorflow_addons as tfa\n",
    "# optimizer=tfa.optimizers.AdamW\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.experimental.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    ),\n",
    "    loss=keras.losses.mean_absolute_error,\n",
    ")\n",
    "# pixelwise mean absolute error is used as loss\n",
    "\n",
    "# save the best model based on the validation KID metric\n",
    "checkpoint_path = \"checkpoints/diffusion_model\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_kid\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(1, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80d717405e3ce327cfc6a10a7c3be3a4a39215d9a17073dca3e8efe1a3c7fabb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
