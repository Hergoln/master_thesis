{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do?\n",
    "\n",
    "Process will look like this:\n",
    "1. Implement/extend generator\n",
    "2. Think of possible errors/bugs errors introducer can introduce to existing samples\n",
    "3. Save samples with introduced bugs as separate dataset (to consider)\n",
    "4. Let model learn on generated correct samples\n",
    "5. Let previously learnt model learn on expanded bugged dataset. This dataset will contain samples paired/connected with bugged samples. In this process correct sample will be provided together with bugged samples (or all bugged samples connected with correct sample) and during training bugged sample will be treated as noised sample and goal of denoising will be to get correct sample back. HAVE TO MODIFIE MODEL FOR IT OR ADD ANOTHER METHOD THAT WILL TRAIN IN THIS WAY OR MAYBE STEERE TRAIN_STEP USING PARAMETER DURING CONSTRUCTION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduction of 'errors' end their repairs (v1)\n",
    "\n",
    "First version of generator outputs simple samples so errors are also probably simple. Thus only those 3 (but really 2 cause first two are the same but different symbols)\n",
    "\n",
    "Errors:\n",
    "* randomly remove operations tokens (mathematical operations) or equal signs or semicolons and shift other tokens by amount of tokens removed. ***\"Ponieważ ta wersja języka jest bardzo prosta to ciężko wymyślić bardziej skomplikwoane błędy do dodania. Należy również zauważyć, że według próbke pomiędzy kolejnymi ID lub literałami (NUM, STRING) powinny znajdować się znaki równości, operacje matematyczne lub średniki. Więc jeżeli model jest w stanie naprawić próbkę, która została zniekształcona za pomocą jednej z powyższych operacji, to istnieje potencjał wykorzystania tej metody w bardziej skomplikowanych przypadkach błędów czy też języków\"***\n",
    "\n",
    "* ~~(there are no functions in this version so maybe not here) add parenthesis after ID that is not a function~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sample = ['char','ID0','(','int','ID1',',','char','ID2',',','char','ID3',')','{','int','ID4',';',\n",
    "'char','ID5',';','printf','(','STRING',',','ID2',')',';','char','ID6','=','ID2','/','ID3',\n",
    "'+','ID2','/','ID0','-','STRING',';','ID0','=','ID3','/','ID6','*','ID3','+','STRING',\n",
    "'*','ID3','+','STRING',';','int', 'ID7', '=', 'NUM', ';', 'ID1', '=', 'ID7', '-', 'ID4', '-',\n",
    "'ID4','/','ID7','+','NUM',';','int','ID8',';','printf','(','STRING',',','ID8',')',\n",
    "';','int','ID9','=','ID8','*','ID8','/','ID7','-','ID7','*','NUM',';','return',\n",
    "'NUM',';','}','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY','EMPTY',\n",
    "'EMPTY','EMPTY','EMPTY','EMPTY','EMPTY']\n",
    "print(len(single_sample))\n",
    "print(\" \".join(single_sample).replace(\";\", \";\\n\").replace(\"{\", \"{\\n\").replace(\"EMPTY\", \"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vvv This cell is going to go entirely into separate py file so it can be reused vvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample is a sequence (list of tokens) of generated/loaded code\n",
    "def remove_token_and_shift_sample_randomized(tokens_to_remove, chance_to_survive):\n",
    "  def apply(sample):\n",
    "    to_return = [token for token in sample if (token not in tokens_to_remove or random.random() < chance_to_survive)]\n",
    "    return to_return + [\"EMPTY\" for _ in range(len(sample) - len(to_return))]\n",
    "  return apply\n",
    "  \n",
    "def remove_token_and_shift_sample(tokens_to_remove):\n",
    "  def apply(sample):\n",
    "    to_return = [token for token in sample if (token not in tokens_to_remove)]\n",
    "    return to_return + [\"EMPTY\" for _ in range(len(sample) - len(to_return))]\n",
    "  return apply\n",
    "\n",
    "class ErrorsIntroducer:\n",
    "  def __init__(self, errors_introducers) -> None:\n",
    "    self.errors_introducers = errors_introducers\n",
    "\n",
    "  '''\n",
    "  no_of_bugged_samples - should be used only in case introducers are based on some kind of randomness and You want to have multiple takes on the same \n",
    "  '''\n",
    "  def apply(self, sample, no_of_takes):\n",
    "    if not no_of_takes or no_of_takes <= 0:\n",
    "      no_of_takes = 1\n",
    "    bugged_sample = sample\n",
    "    samples = []\n",
    "    for _ in range(no_of_takes):\n",
    "      for introducer in self.errors_introducers:\n",
    "        bugged_sample = introducer(bugged_sample)\n",
    "      samples.append(bugged_sample)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introducer = ErrorsIntroducer([remove_token_and_shift_sample_randomized([\";\", \"+\", \"-\", \"/\", \"=\"], 0.5)])\n",
    "out = introducer.apply(single_sample, 5)\n",
    "print(len(out))\n",
    "for each in out:\n",
    "  print(\" \".join(each).replace(\";\", \";\\n\").replace(\"{\", \"{\\n\").replace(\"EMPTY\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_c_v1_lang_generator import fill_vocabulary_c_v1, vocabulary_c_v1\n",
    "fill_vocabulary_c_v1()\n",
    "cv1Dict = {el:idx for idx,el in enumerate(vocabulary_c_v1)}\n",
    "def tokens_to_vals(sample):\n",
    "  return [cv1Dict[token] for token in sample]\n",
    "\n",
    "# load original sample\n",
    "\n",
    "# saving errors\n",
    "original_data_dir_path = \"..\\\\data\\\\testu_testu\"\n",
    "bugged_data_dir_path = original_data_dir_path + \"_bugged\"\n",
    "connection_file_path = bugged_data_dir_path + \"\\\\connections_to_original_index\"\n",
    "connections = {}\n",
    "\n",
    "final_dataset = np.asarray([tokens_to_vals(single_sample)])\n",
    "print(final_dataset.shape)\n",
    "for idx, sample in enumerate(final_dataset):\n",
    "  sample_filename = f\"sample_no{idx}.txt\"\n",
    "  np.savetxt(f\"{original_data_dir_path}\\\\{sample_filename}\", sample, newline=\" \", fmt=\"%u\")\n",
    "\n",
    "  bugged_samples = introducer.apply(sample, 5)\n",
    "  current_connections = []\n",
    "  for no_of_bugged_sample, bugged_sample in enumerate(bugged_samples):\n",
    "    filename = f\"sample_no{idx}_take{no_of_bugged_sample}.txt\"\n",
    "    current_connections.append(filename)\n",
    "    np.savetxt(f\"{bugged_data_dir_path}\\\\{filename}\", bugged_sample, newline=\" \", fmt=\"%u\")\n",
    "  connections[sample_filename] = current_connections\n",
    "# save connections files\n",
    "with open(connection_file_path, 'w') as connectionsFileHandler:\n",
    "  for key in connections:\n",
    "    print(connections[key])\n",
    "    connectionsFileHandler.write(\",\".join([key, *connections[key]]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading \n",
    "with open(connection_file_path, 'r') as connectionsFileHandler:\n",
    "  lines = connectionsFileHandler.readlines()\n",
    "  lines = [line.strip().split(',') for line in lines]\n",
    "  print(lines)\n",
    "  original = lines[0][0]\n",
    "  print(original)\n",
    "  bugged = lines[0][1:]\n",
    "  print(bugged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version for numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vals = tokens_to_vals(single_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample is a sequence (list of tokens) of generated/loaded code\n",
    "def remove_token_and_shift_sample_randomized(tokens_to_remove, chance_to_survive, dictionary, sample_len):\n",
    "  EMPTY = dictionary[\"EMPTY\"]\n",
    "  tokens_to_remove = [dictionary[token] for token in tokens_to_remove]\n",
    "  def apply(samples):\n",
    "    to_return = [[token for token in sample if (token not in tokens_to_remove or random.random() < chance_to_survive)] for sample in samples]\n",
    "    to_return = [sample + [EMPTY for _ in range(sample_len - len(sample))] for sample in to_return]\n",
    "    return to_return\n",
    "  return apply\n",
    "\n",
    "class ErrorsIntroducer:\n",
    "  def __init__(self, errors_introducers) -> None:\n",
    "    self.errors_introducers = errors_introducers\n",
    "\n",
    "  '''\n",
    "  no_of_bugged_samples - should be used only in case introducers are based on some kind of randomness and You want to have multiple takes on the same \n",
    "  '''\n",
    "  def apply(self, samples):\n",
    "    for introducer in self.errors_introducers:\n",
    "      samples = introducer(samples)\n",
    "    return np.asarray(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80d717405e3ce327cfc6a10a7c3be3a4a39215d9a17073dca3e8efe1a3c7fabb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
